# RL Trainer Config for GridGame
# Trains a vision-language model on grid coordinate prediction task

max_steps = 100
max_async_level = 1  # Must match orchestrator config

[model]
# For multimodal training, use a VLM (Vision-Language Model)
name = "Qwen/Qwen2.5-VL-3B-Instruct"

# Attention implementation
attn = "flash_attention_2"

# Trust remote code for VLMs
trust_remote_code = true

# Freeze vision encoder (typical for VLM fine-tuning)
freeze_vision_encoder = true

[optim]
lr = 1e-5  # Increased - VLM examples use 1e-5

